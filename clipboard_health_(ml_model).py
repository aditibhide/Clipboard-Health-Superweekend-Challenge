# -*- coding: utf-8 -*-
"""Clipboard Health (ML Model)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UmDJ5pErFH0me4AY98h4gfZumEQpePU7
"""

# Import necessary libraries
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report

# Additional Analyses and Visualizations

# Create IS_CLAIMED column
df['IS_CLAIMED'] = df['CLAIMED_AT'].notnull().astype(int)

# Select features and target variable
feature_cols = ['RATE', 'DURATION', 'LEAD_TIME_HOURS', 'SLOT', 'SHIFT_DAY_OF_WEEK', 'SHIFT_START_HOUR']
X = df[feature_cols]
y = df['IS_CLAIMED']

# Convert categorical variables
X = pd.get_dummies(X, columns=['SLOT', 'SHIFT_DAY_OF_WEEK'], drop_first=True)

# Handle missing values
X = X.fillna(0)

# Resample the data using SMOTE to handle class imbalance
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, stratify=y_resampled, test_size=0.2, random_state=42)

# Random Forest Classifier with hyperparameter tuning to prevent overfitting
rf_model = RandomForestClassifier(n_estimators=150, random_state=42, class_weight='balanced', max_depth=15, min_samples_split=5, min_samples_leaf=3)
rf_model.fit(X_train, y_train)

# Cross-validation to evaluate model performance
cv_scores = cross_val_score(rf_model, X_resampled, y_resampled, cv=5)
print(f'Cross-validation Accuracy Scores: {cv_scores}')
print(f'Mean Cross-validation Accuracy: {cv_scores.mean()}')

# Evaluate the model on the test set
y_pred = rf_model.predict(X_test)
print(classification_report(y_test, y_pred))

# Feature Importance Analysis
feature_importances = pd.Series(rf_model.feature_importances_, index=X.columns).sort_values(ascending=False)
plt.figure(figsize=(10, 6))
feature_importances.plot(kind='bar')
plt.title('Feature Importance from Random Forest Model')
plt.xlabel('Features')
plt.ylabel('Importance')
plt.tight_layout()
plt.savefig('/content/feature_importance.png')
plt.close()
plt.show()

# Worker Behavior Analysis
# Calculate cancellation and no-show counts
worker_stats = df.groupby('WORKER_ID').agg({
    'SHIFT_ID': 'count',
    'CANCELED_AT': lambda x: x.notnull().sum(),
    'IS_NCNS': 'sum'
}).rename(columns={
    'SHIFT_ID': 'TOTAL_SHIFTS',
    'CANCELED_AT': 'TOTAL_CANCELLATIONS',
    'IS_NCNS': 'TOTAL_NCNS'
})

# Calculate rates
worker_stats['CANCELLATION_RATE'] = worker_stats['TOTAL_CANCELLATIONS'] / worker_stats['TOTAL_SHIFTS']
worker_stats['NCNS_RATE'] = worker_stats['TOTAL_NCNS'] / worker_stats['TOTAL_SHIFTS']

# Plot distribution of cancellation rates
plt.figure(figsize=(10, 6))
sns.histplot(worker_stats['CANCELLATION_RATE'], bins=30, kde=True)
plt.title('Distribution of Worker Cancellation Rates')
plt.xlabel('Cancellation Rate')
plt.ylabel('Number of Workers')
plt.savefig('/content/cancellation_rate_distribution.png')
plt.close()
plt.show()

# Shift Fill Rate Over Time
# Create IS_FILLED column
df['IS_FILLED'] = df['IS_VERIFIED'] | df['IS_NCNS'] | df['CANCELED_AT'].notnull()

# Group by month
monthly_fill_rate = df.groupby(df['SHIFT_MONTH'], observed=True).agg({
    'SHIFT_ID': 'count',
    'IS_FILLED': 'sum'
}).rename(columns={
    'SHIFT_ID': 'TOTAL_SHIFTS',
    'IS_FILLED': 'FILLED_SHIFTS'
})
monthly_fill_rate['FILL_RATE'] = monthly_fill_rate['FILLED_SHIFTS'] / monthly_fill_rate['TOTAL_SHIFTS']

# Plot fill rate over time
plt.figure(figsize=(12, 6))
sns.lineplot(x=monthly_fill_rate.index, y='FILL_RATE', data=monthly_fill_rate, marker='o')
plt.title('Shift Fill Rate Over Time')
plt.xlabel('Month')
plt.ylabel('Fill Rate')
plt.xticks(rotation=45)
plt.savefig('/content/fill_rate_over_time.png')
plt.show()

# Rate Optimization Analysis
# Create rate buckets
df['RATE_BUCKET'] = pd.cut(df['RATE'], bins=np.arange(df['RATE'].min(), df['RATE'].max() + 5, 5))

# Calculate claim rates
claim_rates = df.groupby(['SLOT', 'RATE_BUCKET'], observed=True)['IS_CLAIMED'].mean().reset_index()

# Convert RATE_BUCKET to string for plotting purposes
claim_rates['RATE_BUCKET'] = claim_rates['RATE_BUCKET'].astype(str)

# Plot claim rates by rate offered and shift slot
plt.figure(figsize=(12, 6))
sns.lineplot(x='RATE_BUCKET', y='IS_CLAIMED', hue='SLOT', data=claim_rates, marker='o')
plt.title('Claim Rate by Rate Offered and Shift Slot')
plt.xlabel('Rate Offered ($ per hour)')
plt.ylabel('Claim Rate')
plt.legend(title='Shift Slot')
plt.xticks(rotation=45)
plt.savefig('/content/claim_rate_by_rate_slot.png')
plt.show()

# Lead Time Impact on Shift Outcome
# Boxplot of lead time by shift outcome
plt.figure(figsize=(12, 6))
sns.boxplot(x='SHIFT_OUTCOME', y='LEAD_TIME_HOURS', data=df)
plt.title('Lead Time Distribution by Shift Outcome')
plt.xlabel('Shift Outcome')
plt.ylabel('Lead Time (Hours)')
plt.xticks(rotation=45)
plt.savefig('/content/lead_time_by_shift_outcome.png')
plt.show()

# Worker Engagement Analysis
# Calculate shifts claimed and worked per worker
worker_engagement = df[df['IS_CLAIMED'] == 1].groupby('WORKER_ID').agg({
    'SHIFT_ID': 'count',
    'IS_VERIFIED': 'sum'
}).rename(columns={
    'SHIFT_ID': 'SHIFTS_CLAIMED',
    'IS_VERIFIED': 'SHIFTS_WORKED'
})
worker_engagement['WORK_RATE'] = worker_engagement['SHIFTS_WORKED'] / worker_engagement['SHIFTS_CLAIMED']

# Top 20 workers by shifts claimed
top_workers = worker_engagement.sort_values('SHIFTS_CLAIMED', ascending=False).head(20)

# Plot
plt.figure(figsize=(12, 6))
sns.barplot(x=top_workers.index, y='SHIFTS_CLAIMED', data=top_workers)
plt.title('Top 20 Workers by Shifts Claimed')
plt.xlabel('Worker ID')
plt.ylabel('Shifts Claimed')
plt.xticks(rotation=90)
plt.savefig('/content/top_workers_by_shifts_claimed.png')
plt.show()

# Revenue Analysis
# Revenue from worked shifts
worked_shifts = df[df['IS_VERIFIED'] == True]
total_revenue = worked_shifts['TOTAL_PAY'].sum()
print(f'Total Revenue: ${total_revenue:,.2f}')

# Revenue by slot
revenue_by_slot = worked_shifts.groupby('SLOT')['TOTAL_PAY'].sum()
plt.figure(figsize=(8, 6))
sns.barplot(x=revenue_by_slot.index, y=revenue_by_slot.values)
plt.title('Revenue by Shift Slot')
plt.xlabel('Shift Slot')
plt.ylabel('Total Revenue ($)')
plt.savefig('/content/revenue_by_shift_slot.png')
plt.show()

# Advanced Correlation Analysis
# Pair plot
sns.pairplot(df[['RATE', 'DURATION', 'LEAD_TIME_HOURS', 'TOTAL_PAY', 'IS_CLAIMED']], hue='IS_CLAIMED')
plt.savefig('/content/pairplot_analysis.png')
plt.show()

# Spearman correlation
spearman_corr = df[['RATE', 'DURATION', 'LEAD_TIME_HOURS', 'TOTAL_PAY']].corr(method='spearman')
plt.figure(figsize=(8, 6))
sns.heatmap(spearman_corr, annot=True, cmap='coolwarm')
plt.title('Spearman Correlation Matrix')
plt.savefig('/content/spearman_correlation_matrix.png')
plt.show()